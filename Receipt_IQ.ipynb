{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM87ecSEUmy5cOHQhUqS/Go",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samarjahanahmedburney/Recepitiq/blob/main/Receipt_IQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ttLXQBMy2hF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Optional LLM imports\n",
        "import openai\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 1. IMAGE PREPROCESSING\n",
        "# -------------------------------\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Noise reduction\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Adaptive threshold\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        gray, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY,\n",
        "        11, 2\n",
        "    )\n",
        "\n",
        "    return thresh"
      ],
      "metadata": {
        "id": "nVXR8rF7y3tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 2. OCR\n",
        "# -------------------------------\n",
        "\n",
        "def extract_text(image_path):\n",
        "    processed = preprocess_image(image_path)\n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    text = pytesseract.image_to_string(processed, config=custom_config)\n",
        "    return text\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 3. DATA PARSING\n",
        "# -------------------------------\n",
        "\n",
        "def parse_receipt(text):\n",
        "    lines = text.split(\"\\n\")\n",
        "    items = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "\n",
        "        match = re.search(r'(.+?)\\s+(\\d+[.,]\\d{2})$', line)\n",
        "        if match:\n",
        "            name = match.group(1)\n",
        "            price = float(match.group(2).replace(\",\", \".\"))\n",
        "\n",
        "            items.append({\n",
        "                \"item\": name,\n",
        "                \"price\": price,\n",
        "                \"quantity\": 1\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(items)"
      ],
      "metadata": {
        "id": "OMCY72KkzMwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 4. CATEGORIZATION\n",
        "# -------------------------------\n",
        "\n",
        "def categorize_item(name):\n",
        "    name = name.lower()\n",
        "\n",
        "    if any(word in name for word in [\"milk\", \"cheese\", \"yogurt\"]):\n",
        "        return \"Dairy\"\n",
        "    elif any(word in name for word in [\"bread\", \"cake\", \"bun\"]):\n",
        "        return \"Bakery\"\n",
        "    elif any(word in name for word in [\"chicken\", \"beef\", \"meat\"]):\n",
        "        return \"Meat\"\n",
        "    elif any(word in name for word in [\"chips\", \"snack\", \"chocolate\"]):\n",
        "        return \"Snacks\"\n",
        "    elif any(word in name for word in [\"rice\", \"pasta\", \"flour\"]):\n",
        "        return \"Grains\"\n",
        "    else:\n",
        "        return \"Other\""
      ],
      "metadata": {
        "id": "02fyae4yzfN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 5. SPENDING ANALYSIS\n",
        "# -------------------------------\n",
        "\n",
        "def analyze_spending(df):\n",
        "    df[\"category\"] = df[\"item\"].apply(categorize_item)\n",
        "\n",
        "    category_totals = df.groupby(\"category\")[\"price\"].sum()\n",
        "    total_spending = df[\"price\"].sum()\n",
        "\n",
        "    summary = category_totals.reset_index()\n",
        "    summary[\"percentage\"] = (summary[\"price\"] / total_spending) * 100\n",
        "\n",
        "    return df, summary, total_spending"
      ],
      "metadata": {
        "id": "ieHvulREzhmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 6. LLM ADVICE (OPENAI)\n",
        "# -------------------------------\n",
        "\n",
        "def generate_advice_openai(summary, total):\n",
        "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Here is a spending summary:\n",
        "    {summary.to_string(index=False)}\n",
        "\n",
        "    Total spending: {total}\n",
        "\n",
        "    Give personalized budgeting advice.\n",
        "    Highlight overspending areas.\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "_llFOXrsznnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJyw-dxc0Vdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}